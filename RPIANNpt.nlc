//RPIANNpt Specification (prompts):

---
v1a (Codex IDE GPT5Codex prompt);

Please upgrade RPIANNpt_RPIANNmodel to implement this specification;

I have an input embedding x and a prediction embedding y_hat, all encoded in a single recursive MLP layer; the layer decides what best next action the network should take to iteratively improve the prediction embedding y_hat (with respect to the target output embedding y). For simplicity, assume a large random projection from class targets to prediction/target output embedding y_hat/y, and a large random projection from input to input embedding x.

---
trainLocal (Codex IDE GPT5Codex prompt):

OK please perform this upgrade. When trainLocal=True, then only perform backprop between individual recursive iterations (and never in the input/output embedding layers). If trainLocal=False, then perform full backprop through the entire recursive network.

---
useCNNlayers (Codex IDE GPT5Codex prompt):

input_projection should be changed to an untrained CNN layer when useImageDataset=True (that still produces the correct embedding size

---
useRecursiveLayers (Codex IDE GPT5Codex prompt):

Please implement option useRecursiveLayers=False (while leaving the current implementation for useRecursiveLayers=True unchanged). If useRecursiveLayers=False then;
a) class RPIANNmodel creates independent nonrecursive_layer object (ie parameters) for each layer - instead of a single recursive_layer object.
b) class RPIANNmodel: iterate_prediction() and _train_recursive_locally() functions are updated to execute using these nonrecursive_layer objects (instead of the recursive_layer object).

---
targetProjectionActivationFunction=False (Codex IDE GPT5Codex prompt):

Please implement option targetProjectionActivationFunction=False - the final hidden layer in the network does not have a relu applied (enabling a signed comparison with the signed output of the target projection).

---
subLayerFirstNotTrained (Codex IDE GPT5Codex prompt):

Hi, please implement option subLayerFirstNotTrained=True (only when numberOfSublayers>1)

---
subLayerFirstMixXembedYhatStreamsSeparately (Codex IDE GPT5Codex prompt):

Please implement option subLayerFirstMixXembedYhatStreamsSeparately=True (for case numberOfSublayers >1 and layersFeedConcatInput=True only); it feeds x_embed and y_hat input through separate weights in the first sublayer (then concats their output).

---
subLayerFirstSparse (Codex IDE GPT5Codex prompt):

Please implement option subLayerFirstSparse=True (for case numberOfSublayers >1 and subLayerFirstNotTrained=True only). This initialises the all first sublayer weights to be sparsely connected rather than densly connected, while providing a parameter to set the level of this sparsity.

---
useRPICNN (Codex IDE GPT5Codex prompt):

Please implement option useRPICNN=True (for case useImageDataset=True and useCNNlayers=True only); 
- useRPICNN creates a standard CNN network but with conv and maxpool kernels with stride=1 (the cnn "pixel" space does not shrink or expand each layer), and applies an equal number of kernels per layer.
- similar to the core RPIANN algorithm; when layersFeedConcatInput=True, each RPICNN kernel takes input from both the first x embedding layer and the output of the previous embedding layer.
- similar to the core RPIANN algorithm; when useRecursiveLayers=True, each layer reuses its RPICNN kernels (they are not initialised separately for each layer).

---
useRPICNN (Codex IDE GPT5Codex prompt):

There is no theoretical reason why the num channels for x_embed and y_hat are identical for an RPICNN architecture (for initialiseYhatZero=True).
1. Please upgrade the useRPICNN code to support different number of channels for x_embed. 
2. please replace _build_rpi_cnn_projection with _build_image_projection.
3. please upgrade _build_image_projection to support configurable stride values (ie stride 1 or stride 2).
4. please add bool option useRPIANNimageProjection=False, and set it to False by default. In this case x_embed will have 3 channels (corresponding to the CIFAR image channels).

Please proceed with implementation, but also inform me of any algorithmic issues you encounter when thinking about the new implementation.

---
RPICNNuniqueWeightsPerPixel (Codex IDE GPT5Codex prompt):

Please implement option RPICNNuniqueWeightsPerPixel=True (for case useRPICNN=True). Each pixel of the RPICNN action layer has its own unique CNN kernel weights.